var textForPages = ["Lab Guide                                                            Machine Learning with                                    Pentaho Data Integration (PDI)                                       Credit Card Fraud – randomForest in R","Change log:                   Date         Courseware Version  Microcode        Notes                   June 2020    1.0                  9.0.0.3 – 582","Contents                  Terminology.............................................................................................................................. 1                Prerequisites............................................................................................................................. 2                   Installing Python .................................................................................................................... 2                    Installing Libraries .................................................................................................................. 4                   Google Colab ......................................................................................................................... 5                    Installing R ............................................................................................................................ 6                   Setting R Environment Variables ............................................................................................... 7                   Installing the randomForest Library ..........................................................................................11                    Installing RStudio (Optional) ...................................................................................................12                   Configuring Pentaho Data Integration with R ..............................................................................13                   Verifying Your Installation .......................................................................................................13                 Lab 1: Credit Card Fraud – AutoML ...............................................................................................15                   Objectives ............................................................................................................................15                   Step 1 – Data Preparation........................................................................................................15                    Step 2 – Feature Engineering ...................................................................................................18                   Step 3 – Test Machine Learning Models to Identify the Most Accurate Model ....................................18                      TPOT: py-auto_ml ..............................................................................................................18                     Colab ...............................................................................................................................20                     AutoML Script ....................................................................................................................21                      Python Executor.................................................................................................................23                Lab 2: Credit Card Fraud – randomForest ......................................................................................29                   Objectives ............................................................................................................................29                    Train the Model .....................................................................................................................29                   R Script Executor: Train Model .................................................................................................30                   Predict Fraudulent Credit Card Transactions ..............................................................................33                 Appendix A: Python Script for PDI.................................................................................................38                Appendix C: R Script for Train ......................................................................................................42                Appendix D: R Script for Predict ...................................................................................................43                 Related Information ..................................................................................................................44","This page intentionally  left blank.","Lab Guide: Machine Learning with PDI                     Terminology                  The table below outlines the different course activities:                   Activity                   Description                                              The  Instructor  will  demonstrate  the  workflow,  outlining  the  key                  Demonstration              concept(s). The  student  is  not  expected  to  replicate  the  Instructor’s                                             demonstration; but understand the key concept(s) and workflow.                                              The Instructor will outline the key concepts, features and options.  The                  Lab                        student is expected to follow along with the Instructor so that they                                             understand the key concept(s), features and options for the Exercise.                            The icon indicates an Info Tip. Info Tips help users understand unfamiliar workflows or actions.                           The icon indicates that you need to be careful when implementing or configuring the                         step/option(s).                           The icon indicates a Best Practice. A Best Practice is a method or technique that has been                         generally accepted as a standard way of doing things.                                                                                                          Page 1                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                    Prerequisites                  The following prerequisites need to be completed:                    •  Install Python for Windows                      •  Google Colab                     •  Install R for Windows                      •  Set R Environmental Variables                     •  Install R Studio for Windows                     •  Configure Pentaho Data Integration with R                   Installing Python                  To install Python:                    1.  Download Python from Python for Windows.                      2.  Click on Download Windows x86-64 executable installer on the page.                     3.  Run python-3.8.3-amd64.exe and follow the installation instructions.                                                                                                     Page 2                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                       4.  Ensure you select:                             a.  Customize Installation                            b.  Install launcher                             c.  Add Python 3.8 to PATH                     5.  Keep default options and click Next.                     6.  Ensure you select:                             a.  Install for all users                            b.  Precompile standard library                             c.  Change the Path to: C:\\Python\\Python38                                                    7.  Click Install.                                                                              Page 3                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                    Installing Libraries                 The following libraries need to be installed:                     •  pandas                     •  matplotlib                     •  py4j                      •  numpy                     •  wheel                     •  sklearn                      •  TPOT                 To do this:                     1.  Open a Command Prompt (Admin) window.                     2.  Enter the following command to install pandas: pip install pandas                                              3.  Repeat to download and install the other required libraries:                                                                               Page 4                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                                                You may need to restart your system.                      Google Colab                 Colab is a Python development environment, based on Jupyter Notebooks, that runs in the browser using                Google Cloud. It provides a runtime, fully configured for deep learning libraries, such as Keras, TensorFlow,                PyTorch, and OpenCV.                    •  For further details: Google Colab                     •  Recommended to sync with Google Drive.                                                                                    Page 5                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                    Installing R                 To install R:                     1.  Download R from r-project by selecting a CRAN location (a mirror site) and clicking the                        corresponding link.                      2.  Click Download R for Windows at the top of the page.                     3.  Click install R for the first time at the top of the page.                              4.  Click Download R <version> for Windows.                      5.  Run R-4.0.1-win.exe and follow the installation instructions.                                                                                                             Page 6                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                    Setting R Environment Variables                 To set the R environment variables:                     1.  Go to Control Panel → System → Advanced System Settings.                     2.  Click the Environment Variables button.                     3.  Under System Variables, click: New.                                          4.  In the Variable Name field, enter R_HOME                      5.  Browse for the directory C:\\Program Files\\R\\R-4.0.1                                    6.  Repeat to add the variable R_LIBS_USER                     7.  Browse for the directory C:\\Program Files\\R\\R-4.0.1\\library                                                                                Page 7                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                                     8.  Add to the Path the location of the R executable: %R_HOME%\\bin\\x64                      9.  Ensure the path references rcmd.exe and r.dll.                                            10. Start R.                      11. In the R Console, run the command install.packages('rJava')                                                                                              Page 8                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                                                                    12. If prompted with Would you like to use a personal library instead? click Yes.                                   13. If prompted with the path of the library, click Yes.                      14. When prompted for the CRAN mirror, choose a country, and then click OK.                            You may be denied permission writing to the library folder. You will need to change the                         permission for the folder.                                                                      Page 9                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                                                                                                                                               Page 10                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                    Installing the randomForest Library                 To install the randomForest library:                     1.  Click on the R Console icon.                     2.  Enter the following command: install.packages('randomForest')                                              3.  After randomForest has successfully been installed, type q() to quit the R console.                     4.  Click Yes to close the workplace image.                     5.  Close R.                                                                                          Page 11                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                    Installing RStudio (Optional)                 To install RStudio:                     1.  Download RStudio from RStudio IDE.                     2.  Click on the Download RStudio for Windows button.                                           3.  Run RStudio-1.3.959.exe and follow the installation instructions.                                                                                                          Page 12                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                    Configuring Pentaho Data Integration with R                 In the rJava directory, there is a jri.dll file that needs to be copied into the libswt directory of Spoon:                     1.  Stop Spoon, if it is running.                     2.  Find %R_LIBS_USER%/rJava/jri/x64/jri.dll                      3.  Copy jri.dll to the following directory:                            a.  Windows: [Pentaho directory]/client-tools/data-                               integration/libswt/win64                             b.  Linux: [Pentaho directory]/client-tools/data-                               integration/libswt/linux                 Further details can be found in R on PDI in the Pentaho Data Integration Best Practices library.                    Verifying Your Installation                      1.  Open a new transformation in PDI.                     2.  Drag an R Script Executor step onto the canvas.                     3.  Double-click the step and select the middle tab, R Script. You will see some comments at the top                         of the window:                         # The main output is expected to be a data frame, unless \"Output                         # from script is text\" is checked. So, to output a data frame the                        # last statement in the script should be the name of the frame.                        # In the case that the output is text (as would be seen on the                        # R console), the last statement should be a \"print\" statement in                        # order to print the object required.                     4.  Beneath the comment above, enter this code:                          library(datasets)                        iris                      5.  Once you have entered this code in the R Script tab, click the Test Script button on this tab.                                                                    Page 13                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                                                                                                                                                  Page 14                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                    Lab 1: Credit Card Fraud – AutoML                          Imagine that a direct retailer wants to reduce losses due to orders involving fraudulent use of                        credit cards. They accept orders via phone and their web site, and ship goods directly to the                        customer. Basic customer details, such as customer name, date of birth, billing address and                        preferred shipping address, are stored in a relational database.                        Orders, as they come in, are stored in a database. There is also a report of historical instances of                        fraud contained in a CSV spreadsheet.                   Objectives                 In this guided demonstration, you will:                     •  Prepare Data                     •  Configure Python Executor step.                      •  Build and Train a Forest Tree Model.                     •  Deploy and Test the model.                   Step 1 – Data Preparation                  With the goal of preparing a dataset for ML, we can use PDI to combine these disparate data sources and                engineer some features for learning from it. The following figure shows a transformation demonstrating an                example of just that, and includes some steps for deriving new fields.                 To begin with, customer data is joined from several data sources, and then blended with transactional data                and historical fraud occurrences contained in a CSV file.                     1.  In Spoon, open the following main job: C:\\Machine--                        Learning\\01_Credit_Card\\Lab_01_AutoML\\tr_autoML.ktr                                                                                     Page 15                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                       2.  Browse the various customer data sources:                  csvi-customer_data, where you will find the customer_billing_zip codes, which will be used in                feature engineering:                                       csvi-customer_billing, which references the customer transaction:                                        csvi-customer_transaction:                     •  Customer transaction details                     •  Feature engineering for ship_to_zip                      •  The transaction details (x variables) are used by the decision trees to determine whether the                        transaction is fraudulent (y variable). The Boolean values will need to be changed into numbers                        for the randomForest algorithm.                                                                      Page 16                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                                               csvi-fraud_details_report, which indicates whether historically the transaction was fraudulent:                                                                                                                 Page 17                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                    Step 2 – Feature Engineering                 The Feature Engineering is set to billing zip code = shipping zip code.                     1.  Open the step frmla-billing=shipping.                                     There are steps for deriving additional fields that might be useful for predictive modeling. These include                computing the customer's age, extracting the hour of the day the order was placed, and setting a flag to                indicate whether the shipping and billing addresses have the same zip code.                   Step 3 – Test Machine Learning Models to Identify the Most                 Accurate Model                 So, what does the data scientist do at this point?                 Typically, they will want to get a feel for the data by examining simple summary statistics and visualizations,                followed by applying quick techniques for assessing the relationship between individual attributes (fields)                and the target of interest which, in this example, is the reported_as_fraud_historic field.                 Following that, if there are attributes that look promising, quick tests with common supervised classification                algorithms will be next on the list. This comprises the initial stages of experimental data mining – that is, the                process of determining which predictive techniques are going to give the best result for a given problem.                  TPOT: py-auto_ml                 A Tree-based Pipeline Optimization Tool for Automating Machine Learning (TPOT) is a Python Automated                Machine Learning tool that optimizes machine learning pipelines using genetic programming. TPOT will                automate the  most  tedious  part  of  machine  learning by  intelligently  exploring  thousands  of  possible                pipelines to find the best one for your data.                                                                     Page 18                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                   One of the most useful tools for writing and executing Python script is Google Colab.                     1.  Run the transformation C:\\Machine--                        Learning\\01_Credit_Card\\Lab_01_AutoML\\tr_autoML.ktr                                                           2.   Open the file C:\\Machine--                        Learning\\01_Credit_Card\\Lab_01_AutoML\\data\\TPOT.csv                                   This will be the dataset used for autoML in Colab.                                                                             Page 19                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                    Colab                 The following code overviews the steps:                    1.  In a Chrome browser, open                        https://colab.research.google.com/notebooks/intro.ipynb                      2.  Ensure you have connected to the hosted runtime.                               If you wish to browse the finished script:                    1.  Click on File → Upload notebook.                         C:\\Machine--                        Learning\\01_Credit_Card\\Lab_01_AutoML\\scripts\\credit_card_fraud.ipynb                      2.  Save the Notebook using File → Save                           We recommend that you save either to GitHub or Google Drive.                                                                                           Page 20                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                    AutoML Script                 These are the code sections for the Jupyter file credit card fraud.ipynb:                    1.  Install the TPOT libraries:                          # Installs TPOT libraries.                        !pip install tpot                     2.  Run the step:                                                                                                                             Page 21                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                       3.  Import libraries:                          import numpy as np                        import pandas as pd                        from tpot import TPOTClassifier                         from sklearn import preprocessing                        from sklearn.model_selection import train_test_split                     4.  Import dataset from C:\\Machine--                        Learning\\01_Credit_Card\\Lab_01_AutoML\\data\\TPOT.csv:                          from google.colab import files                        uploaded = files.upload()                         for fn in uploaded.keys():                          print('User uploaded file \"{name}\" with length {length} bytes'.format(                              name=fn, length=len(uploaded[fn])))                         dataset = pd.read_csv('TPOT.csv', sep= ';', header=None)                        x = dataset.iloc[:, :-1].values                         y = dataset.iloc[:, 8].values                     5.  Add column headers:                          dataset.columns =                        ['first_time_customer','order_dollar_amount','num_items','age','web_order',                        'total_transactions_to_date','hour_of_day','billing_shipping_zip_equal','re                        ported_as_fraud_historic']                     6.  Convert dataset to numpy array and fit data (optional):                          x = dataset.iloc[:,0:-1].values                        min_max_scaler = preprocessing.MinMaxScaler()                        x_scaled = min_max_scaler.fit_transform(x)                        X=np.asarray(x_scaled)                        y=np.asarray(dataset.iloc[:,-1])                     7.  Split the dataset. 75% used for test.                          X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.75,                        random_state=None)                                                                   Page 22                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                       8.  Run TPOT Classifier:                          tpot = TPOTClassifier(generations=1, verbosity=2, population_size=100,                        scoring='accuracy', n_jobs = -1, config_dict='TPOT light')                         tpot.fit(X_train, y_train)                        output_score=str(tpot.score(X_test, y_test))                        print(tpot.fitted_pipeline_)                     9.  Export Pipeline as Python script:                          tpot.export('tpot_exported_credit_card_pipeline.py')                        from google.colab import files                        files.download('tpot_exported_credit_card_pipeline.py')                     Python Executor                 The script has been tested and is now ready for deployment in PDI.                     1.  Enable the rest of the hops in the transformation, except: Model Catalogue (table):                                                           2.  Open the step py-auto_ml                                                                Page 23                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                       3.  Ensure you set the path to Python:                                  For further details on the script, see Appendix A.                  To ensure the script does not take a long time to process, the following TPOT parameters have been set:                        tpot = TPOTClassifier(generations=1, verbosity=2,population_size=100,                        config_dict='TPOT light')                           For further details on TPOT parameters, see Appendix B.                      4.  Click on the Input tab.                             a.  Use this tab to make selections for moving data from PDI fields to Python variables.                            b.  The All rows option is commonly used for data frames. A data frame is used for storing                                data tables and is composed of a list of vectors of equal length.                            c.  Select the All rows option to process all your data at once, for example, using the Python                               list of dictionaries.                    Option                     Description                                              Use the plus sign button to add a Python variable to the input mapping for                  Available variables        the script used in the transformation. You can remove the Python variable                                             by clicking the X icon.                                              Enter the name of the Python variable. The list of available variables will                  Variable name                                             update automatically.                                              Specify the name of the input step to map from. It can be any step in the                  Step                       parent transformation with an  outgoing  hop  connected to  the  Python                                             Executor step.                                                                               Page 24                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                      Option                     Description                                             Specify the  data  structure from which  you  want  to  pull the  fields  for                                             mapping. You can select one of the following:                                                 •  Pandas  data  frame:  the  tabular  data  structure  for                                                     Python/Pandas.                  Data structure                                                 •  NumPy array: the table of  values, all the  same type, which  is                                                     indexed by a tuple of positive integers.                                                 •  Python List of Dictionaries: each row in the PDI stream becomes                                                     a Python dictionary. All the dictionaries are put into a Python list.                       5.  The Mapping table contains the following field properties:                   Field Property             Description                                              The value of the Python data structure field to which you want to map the                  Data structure field                                             PDI field.                                              The value of the data structure type assigned to the data structure field to                  Data structure type                                             which you want to map the PDI field.                                             The name of the PDI field which contains the vector data stored in the                  PDI field                                             mapped Python variable.                                              The value of the data type assigned to the PDI field, such as a date, a                  PDI data type                                             number, or a timestamp.                       6.  Select the Get fields button to populate the table with fields from the input step(s) in your                        transformation. If necessary, you can modify your selections.                            For further details, see Python Executor.                                                                                       Page 25                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                                                                          •  The cust variable defines the dataframe in the Python script using iloc:                          x = dataset.iloc[:,1:-1].values                     •  The dataframe is pulled from the PDI step sv-changes_to_numbers.                 From this list, for the purposes of predictive modeling, we can drop the customer name, ID fields, email                addresses, phone  numbers and physical addresses. These  fields are unlikely to be  useful for  learning                purposes and, in fact, can be detrimental due to the large number of distinct values they contain.                    7.  Click on the Output tab.                     8.  The output of model.df dataframe, from the script:                          model_df=pd.DataFrame(model_list,columns=['pipe','generation','mutation','c                        rossover','predecessor','operator','cv'])                         is converted back to PDI fields.                                                               Page 26                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                       9.  Examine the Logging.                      10. Sort by Cross_Validation_Performance:                                        The output from the TPOT is tidied up before writing the results to a model catalogue file.                    •  Filter – removes invalid results                      •  Select values – orders and renames some of the output fields                     •  String Operations – trims data stream field                     •  Text file output – output results to the text file model_catalogue.txt                      •  Microsoft Excel Writer – output results to the Excel workbook model_catalogue.xlsx                                                                                    Page 27                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                    What does this mean?                For the First Generation, the best algorithm pipeline run is DecisionTree with a scoring of 0.844 and accuracy                of 0.84746 (figure used to judge the quality of the pipeline).                    11. Open the Excel file C:\\Machine--                         Learning\\01_Credit_Card\\Lab_01_AutoML\\output\\model_catalogue.xlsx                                     Conclusion                 The best pipeline to use (with 85% accuracy) for this dataset is based on Decision Trees with a minimum of                eight trees.                It may also be worth looking at KNeighbors Classifier.                 The object of using TPOT is to point you in the right direction for selecting the appropriate algorithm.                           The results will be different each time you run the TPOTClassifier.                                                                                             Page 28                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                    Lab 2: Credit Card Fraud – randomForest                          The results from TPOT point to using a Decision Tree algorithm.                   Objectives                  In this guided demonstration, you will:                    •  Train a randomForest model in R.                      •  Deploy your model.                     •  Predict fraudulent credit card transactions.                  The model that will be used is randomForest.                  Train the Model                     1.  In Spoon, open the following main job: C:\\Machine--                         Learning\\01_Credit_Card\\Lab_02_Credit_Card_Fraud\\jb_fraud_main_job.kjb                                           2.  Let’s look at the transformation that trains for the model. Right-click on the train_model                        transformation and select Open Referenced Object → Transformation.                                                                             Page 29                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                                                       For an overview of the steps, see the previous Lab 1: Credit Card Fraud – AutoML.                     R Script Executor: Train Model                      1.  Double-click on the rscrpt-train_model_randomForest step to bring up the configuration settings.                     2.  Under the Configure tab, ensure the Input Frames points to the step name sv-                         convert_booleans_to_numbers and the R Frame name train.                                                                                                Page 30                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                       3.  Set Row Handling to Number of Rows to Process: All.                      4.  Select the R script tab.  Copy and paste the code snippets based on the Comments.                                                                    5.  The required script is located at C:\\Machine--                        Learning\\Lab_02_Credit_Card_Fraud\\scripts\\train_model.txt                      6.  Click on the Output tab.                                                                                  Page 31                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                                            7.  Run the transformation.                                                     8.  Check that the model has been saved in C:\\Machine--                         Learning\\01_Credit_Card\\Lab_02_Credit_Card_Fraud\\scripts\\rf.rdata                                                                            Page 32                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                    Predict Fraudulent Credit Card Transactions                 Let’s look at the transformation that predicts fraudulent credit card activity based on our trained model.                     1.  Right-click on the predict_model transformation and select Open Referenced Object →                        Transformation.                                                          2.  Double-click on the rscrpt-predict step to bring up the configuration settings.                      3.  Under the Configure tab, ensure the Input Frames points to the step name sv-                        convert_booleans_to_numbers and that the R Frame name is test.                                                                                      Page 33                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                                                                       To remove any bias from the dataset, the complete dataset is randomly sampled (mixed up).                     4.  Select the R script tab.  Copy and paste the code snippets based on the Comments.                                                                                               Page 34                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                                                                  5.  The required script is located at C:\\Machine--                        Learning\\01_Credit_Card\\Lab_02_Credit_Card_Fraud\\scripts\\predict_model.                        txt                      6.  Click on the Output tab.                                                                                           Page 35                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                                                         7.  Run the transformation.                                                     8.  Ensure all the steps have completed.                                                                       Page 36                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                       9.  Open the Excel workbook C:\\Machine--                        Learning\\01_Credit_Card\\Lab_02_Credit_Card_Fraud\\output\\credit_card_pre                         dict.xlsx                                       The complete solution can be found at C:\\Machine--                         Learning\\01_Credit_Card\\Lab_02_Credit_Card_Fraud\\solution                                                                                                                      Page 37                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                    Appendix A: Python Script for PDI                          # the following libraries need to be installed (see pre-requisites)                        # pandas                        # matplotlib                         # py4j                        # numpy                        # TPOT                         # import required libraries                         import pandas as pd                        import numpy as np                         from tpot import TPOTClassifier                        from sklearn import preprocessing                         from sklearn.model_selection import train_test_split                         # the dataset is referenced in the step: sv-change_to_numbers                        # independent variables (x) are referenced starting at row 1: col 1. -1                        references all columns apart from the last                        x = dataset.iloc[:,1:-1].values                         # transform features by scaling each feature to a given range                         min_max_scaler = preprocessing.MinMaxScaler()                         # compute the data minimum and maximum for scaling, then transform.                        x_scaled = min_max_scaler.fit_transform(x)                          # optional – change to numpy array                        X=np.asarray(x_scaled)                        y=np.asarray(dataset.iloc[:,-1])                         # split the dataset into train and test. Test size is set at 75% of dataset                        (10,000 rows)                        # further details on random_state:                        #                        https://het.as.utexas.edu/HET/Software/Numpy/reference/generated/numpy.rand                        om.RandomState.html                                                                Page 38                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                           X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.75,                        random_state=None)                          # set TPOT parameters (see Appendix: B for further details)                        tpot = TPOTClassifier(generations=1, verbosity=2, population_size=100,                        scoring='accuracy', config_dict='TPOT light')                         tpot.fit(X_train, y_train)                        output_score=str(tpot.score(X_test, y_test))                         # export TPOT results as python script                         tpot.export('tpot_creditcard_pipeline.py')                         # print the TPOT result                        print(tpot.score(X_test, y_test))                         # PDI output fields which are defined in a dataframe which is mapped to a                        PDI output field: model_df                        model_name=[x[0] for x in tpot.evaluated_individuals_.items()]                        model_gen=[x[1]['generation'] for x in tpot.evaluated_individuals_.items()]                         model_mut=[x[1]['mutation_count'] for x in                        tpot.evaluated_individuals_.items()]                        model_cross=[x[1]['crossover_count'] for x in                        tpot.evaluated_individuals_.items()]                        model_predec=[x[1]['predecessor'] for x in                        tpot.evaluated_individuals_.items()]                         model_opp=[x[1]['operator_count'] for x in                        tpot.evaluated_individuals_.items()]                        model_cv=[str(y[1]['internal_cv_score']) for y in                        tpot.evaluated_individuals_.items()]                        model_list=list(zip(model_name,model_gen,model_mut,model_cross,model_predec                        ,model_opp,model_cv))                         model_df=pd.DataFrame(model_list,columns=['pipe','generation','mutation','c                        rossover','predecessor','operator','cv'])                                                                               Page 39                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                    Appendix B: TPOT Parameters                    Parameter              Valid values                   Effect                                                                         The number of generations to run                                                                        pipeline optimization over. Generally,                                                                        TPOT will work better when you give it                  generation             Any positive integer           more generations (and therefore time) to                                                                        optimize over. TPOT will evaluate                                                                        generations x population_size                                                                        number of pipelines in total.                                                                          The number of individuals in the GP                                                                        population. Generally, TPOT will work                                                                        better when you give it more generations                  population_size        Any positive integer           (and therefore time) to optimize over.                                                                        TPOT will evaluate generations x                                                                        population_size number of pipelines                                                                        in total.                                                                         The mutation rate for the genetic                                                                        programming algorithm in the range                                                                        [0.0, 1.0]. This tells the genetic                  mutation_rate          [0.0, 1.0]                     programming algorithm how many                                                                        pipelines to apply random changes to                                                                        every generation. We don't recommend                                                                        that you tweak this parameter unless you                                                                        know what you're doing.                                                                         The crossover rate for the genetic                                                                        programming algorithm in the range                                                                        [0.0, 1.0]. This tells the genetic                   crossover_rate         [0.0, 1.0]                     programming algorithm how many                                                                        pipelines to “breed\" every generation. We                                                                        don't recommend that you tweak this                                                                        parameter unless you know what you're                                                                        doing.                                                                          The number of folds to evaluate each                                                                        pipeline over in k-fold cross-validation                  num_cv_folds           [2, 10]                                                                        during the TPOT pipeline-optimization                                                                        process.                                                                            Page 40                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                      Parameter              Valid values                   Effect                                         'accuracy',                                         'adjusted_rand_score',                                         'average_precision',                                         'f1', 'f1_macro',                                         'f1_micro',                                         'f1_samples',                                         'f1_weighted',                                         'log_loss',                                         'mean_absolute_error',         Function used to evaluate the quality of a                                         'mean_squared_error',          given pipeline for the problem. By                                         'median_absolute_error',  default, balanced accuracy is used for                                         'precision',                   classification and mean squared error is                  scoring                'precision_macro',             used for regression. TPOT assumes that                                         'precision_micro',             any function with \"error\" or \"loss\" in the                                         'precision_samples',                                         'precision_weighted',          name is meant to be minimized, whereas                                         'r2', 'recall',                any other functions will be maximized.                                         'recall_macro',                                         'recall_micro',                                         'recall_samples',                                         'recall_weighted',                                         'roc_auc' or a callable                                         function with signature                                         scorer(y_true, y_pred)                                                                          How many minutes TPOT has to optimize                  max_time_mins          Any positive integer           the pipeline. This setting will override the                                                                        generations parameter.                                                                         The random number generator seed for                                                                        TPOT. Use this to make sure that TPOT                  random_state           Any positive integer           will give you the same results each time                                                                        you run it against the same dataset with                                                                        that seed.                                                                         How much information TPOT                                                                        communicates while it's running. 0 =                  verbosity              {0, 1, 2, 3}                   none, 1 = minimal, 2 = high, 3 = all. A                                                                        setting of 2 or higher will add a progress                                                                        bar to calls to fit().                                                                         Flag indicating whether the TPOT version                  disable_update_check   [True, False]                                                                        checker should be disabled.                           Further details can be found at Using TPOT.                                                                       Page 41                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                    Appendix C: R Script for Train                          # the following packages need to be installed (see pre-requisites)                        # rJava                        # randomForest                          # load randomForest package                        library(randomForest)                         # the dataset is referenced in the step: sv-convert_booleans_to_numbers                         # assign the dataframe: train to variable: train.df                        train.df <- as.data.frame(train)                         # train model with 8 trees takes about 50 seconds on this VM                        # declare variable rf assigned the results                         # ( y) dependent variable = train.df (dataset) reported_as_fraud_historic                        (column)                        # ~ (tilde) . (point) = (x) independent variables                        rf <- randomForest(train.df$reported_as_fraud_historic ~ ., train.df,                        ntree=8, importance=TRUE)                         # save model to output folder: Note no spaces and double backslashes are                        required.                        save(rf, file=\"C:\\\\Machine--                        Learning\\\\01_Credit_Card\\\\Lab_02_Credit_Card_Fraud\\\\train_model_output\\\\rf.                        rdata\")                         # print message ok to indicate no probs..                         # declare variable: ok assigned with the value “Finished”                        ok <- \"Finished\"                         # assign variable ok to dataframe: ok.df                        ok.df <- as.data.frame(ok)                         ok.df                                                                        Page 42                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                    Appendix D: R Script for Predict                          # the following packages need to be installed (see pre-requisites)                        # rJava                        # randomForest                          # load randomForest package                        library(randomForest)                         # the dataset is referenced in the step: sv-convert_booleans_to_numbers                         # assign the dataframe: test to variable: test.df                        test.df <- as.data.frame(test)                         # load randomForest Model                        load(\"C:\\\\Machine--                        Learning\\\\01_Credit_Card\\\\Lab_02_Credit_Card_Fraud\\\\train_model_output\\\\rf.                        rdata\")                         # declare a variable pred which is assigned the results of using the                        predict function                         # predict function runs our randomForest model against test.df = newdata                        # predict with new test data                        pred <- predict(rf, newdata = test.df)                         # assign pred dataframe to pred.df variable                        pred.df <- as.data.frame(pred)                          # prepare output data                        # using cbind function to bind pred.df to test.df                        submission <- data.frame(cbind(test.df,pred.df))                          # output data                        submission                                                                         Page 43                                                  © Hitachi Vantara LLC 2020. All Rights Reserved","Lab Guide: Machine Learning with PDI                    Related Information                  Here are some links to information that you may find helpful while using this lab guide:                    •  Google Colab                    •  Pentaho Data Integration Best Practices Library                    •  Python Executor                    •  Python for Windows                    •  r-project                    •  RStudio IDE                                                                                                                               Page 44                                                  © Hitachi Vantara LLC 2020. All Rights Reserved"];