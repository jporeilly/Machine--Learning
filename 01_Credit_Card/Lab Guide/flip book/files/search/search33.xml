Lab Guide: Machine Learning with PDI:@0.388725:0.058508:0.610582:0.058508:0.610582:0.048407:0.388725:0.048407:0.006536:0.006536:0.007830:0.002614:0.009137:0.007830:0.003908:0.007830:0.006536:0.003908:0.002614:0.010458:0.006536:0.006523:0.007830:0.003908:0.007830:0.006536:0.002614:0.006536:0.006536:0.006536:0.005216:0.007830:0.003908:0.007830:0.007830:0.002614:0.010444:0.003908:0.003922:0.007830:0.002614:0.007843:0.009137:0.003804
 :@0.611242:0.059663:0.614902:0.059663:0.614902:0.045522:0.611242:0.045522:0.003660
Page 29:@0.477745:0.958381:0.522745:0.958381:0.522745:0.948280:0.477745:0.948280:0.007843:0.006536:0.007830:0.006536:0.002660:0.006536:0.007059
 :@0.522271:0.959537:0.525931:0.959537:0.525931:0.945395:0.522271:0.945395:0.003660
© Hitachi Vantara LLC 2020. All Rights Reserved:@0.395310:0.983088:0.606510:0.983088:0.606510:0.975007:0.395310:0.975007:0.009140:0.002604:0.006536:0.002614:0.003911:0.005229:0.005218:0.006525:0.002614:0.001307:0.006525:0.005229:0.005229:0.002614:0.005229:0.003922:0.005229:0.001435:0.005229:0.005229:0.006584:0.002614:0.005229:0.005229:0.005229:0.005229:0.002614:0.002604:0.005229:0.002614:0.002614:0.002604:0.006536:0.002614:0.005229:0.005229:0.003911:0.003922:0.002604:0.006536:0.005229:0.003922:0.005229:0.003922:0.005218:0.005229:0.005908
 :@0.606013:0.984821:0.609673:0.984821:0.609673:0.970680:0.606013:0.970680:0.003660
Lab 2: Credit Card Fraud   randomForest  :@0.117810:0.125539:0.713325:0.125539:0.713325:0.100255:0.117810:0.100255:0.017047:0.017047:0.018356:0.007820:0.018324:0.009227:0.005137:0.020908:0.011779:0.018324:0.018356:0.007853:0.010471:0.007820:0.020908:0.017047:0.011779:0.018356:0.006544:0.018291:0.011779:0.017047:0.018324:0.018356:0.006544:0.018284:0.006536:0.011779:0.017047:0.018356:0.018356:0.018324:0.027518:0.018291:0.018324:0.011779:0.018324:0.015706:0.010363:0.006536:0.006544
–:@0.471209:0.125539:0.488878:0.125539:0.488878:0.100255:0.471209:0.100255:0.017669
The results from TPOT point to using a Decision Tree algorithm. :@0.176716:0.159475:0.635588:0.159475:0.635588:0.146344:0.176716:0.146344:0.009142:0.009142:0.009142:0.002617:0.006525:0.009142:0.007851:0.009142:0.005217:0.005234:0.007851:0.002617:0.005234:0.006525:0.009142:0.014359:0.002617:0.009142:0.010434:0.011742:0.009142:0.002617:0.009142:0.009142:0.003925:0.009142:0.005234:0.002617:0.005234:0.009142:0.003908:0.009142:0.007851:0.003925:0.009142:0.009142:0.002617:0.009125:0.002617:0.011742:0.009142:0.007851:0.003925:0.007851:0.003925:0.009142:0.009142:0.002617:0.009142:0.006525:0.009142:0.009142:0.002617:0.009125:0.005217:0.009142:0.009142:0.006525:0.003925:0.005234:0.009142:0.014359:0.006116:0.003399
Objectives :@0.117810:0.215105:0.244779:0.215105:0.244779:0.194871:0.117810:0.194871:0.018303:0.014375:0.006546:0.014349:0.013040:0.009112:0.006546:0.013040:0.014349:0.012071:0.005237
In this guided demonstration, you will: :@0.117810:0.242392:0.398709:0.242392:0.398709:0.229261:0.117810:0.229261:0.005217:0.009142:0.002617:0.005234:0.009142:0.003925:0.007851:0.003908:0.009142:0.009142:0.003925:0.009142:0.009142:0.009142:0.003908:0.009142:0.009142:0.014359:0.009142:0.009142:0.007851:0.005234:0.006525:0.009125:0.005234:0.003925:0.009142:0.009142:0.005217:0.002617:0.007851:0.009142:0.009142:0.002617:0.013102:0.003892:0.005217:0.005217:0.005792:0.003399
•:@0.147917:0.266725:0.155734:0.266725:0.155734:0.250692:0.147917:0.250692:0.007817
 :@0.155760:0.266646:0.160484:0.266646:0.160484:0.252005:0.155760:0.252005:0.004724
Train a :@0.176716:0.267644:0.229718:0.267644:0.229718:0.254513:0.176716:0.254513:0.009142:0.006525:0.009125:0.003925:0.009142:0.002617:0.009125:0.003399
randomForest:@0.229052:0.266358:0.351439:0.266358:0.351439:0.252951:0.229052:0.252951:0.010434:0.010434:0.010434:0.010434:0.010434:0.010434:0.009142:0.010434:0.009142:0.010434:0.010434:0.010196
 model in R. :@0.350784:0.267644:0.436650:0.267644:0.436650:0.254513:0.350784:0.254513:0.002598:0.014359:0.009142:0.009142:0.009142:0.003925:0.002617:0.003925:0.009142:0.002617:0.010626:0.005229:0.003399
•:@0.147917:0.302142:0.155734:0.302142:0.155734:0.286109:0.147917:0.286109:0.007817
 :@0.155760:0.302063:0.160484:0.302063:0.160484:0.287422:0.155760:0.287422:0.004724
Deploy your model. :@0.176716:0.303061:0.322761:0.303061:0.322761:0.289930:0.176716:0.289930:0.011742:0.009142:0.009142:0.005217:0.009142:0.007851:0.002617:0.007851:0.009142:0.009142:0.006525:0.002617:0.014556:0.009142:0.009142:0.009142:0.005301:0.005229:0.003399
•:@0.147917:0.336523:0.155734:0.336523:0.155734:0.320490:0.147917:0.320490:0.007817
 :@0.155760:0.336444:0.160484:0.336444:0.160484:0.321803:0.155760:0.321803:0.004724
Predict fraudulent credit card transactions. :@0.176716:0.337442:0.490294:0.337442:0.490294:0.324311:0.176716:0.324311:0.010434:0.006525:0.009142:0.009142:0.003925:0.007851:0.005234:0.002696:0.005261:0.006525:0.009125:0.009142:0.009142:0.009142:0.005217:0.009142:0.009142:0.005234:0.002777:0.007843:0.006525:0.009142:0.009142:0.003925:0.005234:0.002680:0.007876:0.009125:0.006525:0.009142:0.002658:0.005278:0.006525:0.009125:0.009142:0.007851:0.009125:0.007851:0.005234:0.003925:0.009142:0.009142:0.007967:0.005245:0.003399
The model that will be used is :@0.117810:0.371811:0.333219:0.371811:0.333219:0.358680:0.117810:0.358680:0.009142:0.009142:0.009142:0.002617:0.014359:0.009142:0.009142:0.009142:0.005217:0.002617:0.005234:0.009142:0.009125:0.005234:0.002617:0.013102:0.003892:0.005217:0.005217:0.002617:0.009142:0.009142:0.002617:0.009142:0.007851:0.009142:0.009530:0.002614:0.003922:0.007843:0.003399
randomForest:@0.333775:0.370524:0.456386:0.370524:0.456386:0.357117:0.333775:0.357117:0.010458:0.010458:0.010458:0.010458:0.010458:0.010458:0.010458:0.009149:0.010458:0.009149:0.010458:0.010196
. :@0.455474:0.371811:0.464150:0.371811:0.464150:0.358680:0.455474:0.358680:0.005278:0.003399
Train the Model :@0.117810:0.423375:0.302345:0.423375:0.302345:0.403142:0.117810:0.403142:0.014375:0.010421:0.014349:0.006546:0.014375:0.003928:0.009112:0.014375:0.014349:0.005237:0.020948:0.014375:0.014375:0.014349:0.008181:0.005237
1. In Spoon, open the following main job: :@0.147917:0.450662:0.456258:0.450662:0.456258:0.437531:0.147917:0.437531:0.009150:0.004792:0.014857:0.005217:0.009142:0.002617:0.010434:0.009142:0.009142:0.009142:0.009296:0.005229:0.002614:0.009142:0.009142:0.009142:0.009142:0.002617:0.005234:0.009142:0.009142:0.002617:0.005234:0.009142:0.005217:0.005217:0.009142:0.013102:0.003892:0.009142:0.009142:0.002617:0.014359:0.009125:0.003925:0.009142:0.002992:0.003922:0.009142:0.009142:0.005244:0.003399
 :@0.160989:0.449664:0.165713:0.449664:0.165713:0.435023:0.160989:0.435023:0.004724
C:\Machine--:@0.455474:0.449375:0.578252:0.449375:0.578252:0.435968:0.455474:0.435968:0.010458:0.010490:0.010474:0.010434:0.010434:0.010434:0.010434:0.009142:0.010434:0.009390:0.010458:0.010196
Learning\01_Credit_Card\Lab_02_Credit_Card_Fraud\jb_fraud_main_job.kjb:@0.176716:0.471623:0.864327:0.471623:0.864327:0.458216:0.176716:0.458216:0.010434:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010657:0.009150:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009575:0.010458:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.011121:0.009150:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010196
 :@0.863840:0.472910:0.867239:0.472910:0.867239:0.459778:0.863840:0.459778:0.003399
 :@0.791879:0.712556:0.795278:0.712556:0.795278:0.699425:0.791879:0.699425:0.003399
2.:@0.147917:0.734791:0.161859:0.734791:0.161859:0.721660:0.147917:0.721660:0.009150:0.004792
 :@0.160989:0.733793:0.165713:0.733793:0.165713:0.719152:0.160989:0.719152:0.004724
Let’s look at the transformation that :@0.176716:0.734791:0.437412:0.734791:0.437412:0.721660:0.176716:0.721660:0.009125:0.009142:0.005234:0.002617:0.007851:0.002617:0.005217:0.009142:0.009142:0.009125:0.002617:0.009125:0.005234:0.002617:0.005234:0.009142:0.009142:0.003908:0.005234:0.006525:0.009125:0.009142:0.007851:0.005234:0.009142:0.006525:0.014359:0.009125:0.005234:0.003925:0.009142:0.009142:0.002617:0.005234:0.009142:0.009125:0.005234:0.003399
trains for the model. Right-click on the :@0.437173:0.734791:0.716596:0.734791:0.716596:0.721660:0.437173:0.721660:0.005228:0.006537:0.009125:0.003925:0.009142:0.007851:0.002617:0.005234:0.009142:0.006525:0.002617:0.005234:0.009142:0.009142:0.002617:0.014359:0.009142:0.009142:0.009142:0.005217:0.005533:0.002614:0.010451:0.003925:0.009142:0.009142:0.005280:0.007843:0.007851:0.005217:0.003925:0.007851:0.009125:0.002617:0.009142:0.009142:0.002617:0.005234:0.009142:0.009142:0.003399
train_model:@0.715964:0.734791:0.807525:0.734791:0.807525:0.721660:0.715964:0.721660:0.006525:0.006542:0.009108:0.005251:0.009142:0.007851:0.014359:0.009142:0.009142:0.009142:0.005353
 :@0.807598:0.734791:0.810997:0.734791:0.810997:0.721660:0.807598:0.721660:0.003399
transformation and select :@0.176716:0.759059:0.366901:0.759059:0.366901:0.745927:0.176716:0.745927:0.005229:0.006525:0.009125:0.009142:0.007851:0.005234:0.009142:0.006525:0.014359:0.009125:0.005234:0.003925:0.009142:0.009142:0.002617:0.009125:0.009142:0.009142:0.002617:0.007851:0.009142:0.005217:0.009142:0.007851:0.005234:0.003399
Open Referenced Object:@0.366503:0.759059:0.546209:0.759059:0.546209:0.745927:0.366503:0.745927:0.011742:0.009142:0.009142:0.009142:0.002617:0.010451:0.009142:0.006525:0.009142:0.006542:0.009142:0.009142:0.007851:0.009142:0.009142:0.002617:0.011742:0.009142:0.005217:0.009142:0.007851:0.005982
   :@0.547108:0.759059:0.570147:0.759059:0.570147:0.745927:0.547108:0.745927:0.003399:0.016242:0.003399
→:@0.549706:0.757995:0.566342:0.757995:0.566342:0.743498:0.549706:0.743498:0.016637
Transformation:@0.569363:0.759059:0.684952:0.759059:0.684952:0.745927:0.569363:0.745927:0.009142:0.006542:0.009108:0.009193:0.007851:0.006525:0.009142:0.006542:0.013068:0.009108:0.005268:0.005217:0.009142:0.009737
. :@0.684559:0.759059:0.693186:0.759059:0.693186:0.745927:0.684559:0.745927:0.005229:0.003399
 :@0.811520:0.910732:0.814918:0.910732:0.814918:0.897600:0.811520:0.897600:0.003399