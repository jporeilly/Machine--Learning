Lab Guide: Machine Learning with PDI:@0.388725:0.058508:0.610582:0.058508:0.610582:0.048407:0.388725:0.048407:0.006536:0.006536:0.007830:0.002614:0.009137:0.007830:0.003908:0.007830:0.006536:0.003908:0.002614:0.010458:0.006536:0.006523:0.007830:0.003908:0.007830:0.006536:0.002614:0.006536:0.006536:0.006536:0.005216:0.007830:0.003908:0.007830:0.007830:0.002614:0.010444:0.003908:0.003922:0.007830:0.002614:0.007843:0.009137:0.003804
 :@0.611242:0.059663:0.614902:0.059663:0.614902:0.045522:0.611242:0.045522:0.003660
Page 41:@0.477745:0.958381:0.522745:0.958381:0.522745:0.948280:0.477745:0.948280:0.007843:0.006536:0.007830:0.006536:0.002660:0.006536:0.007059
 :@0.522271:0.959537:0.525931:0.959537:0.525931:0.945395:0.522271:0.945395:0.003660
© Hitachi Vantara LLC 2020. All Rights Reserved:@0.395310:0.983088:0.606510:0.983088:0.606510:0.975007:0.395310:0.975007:0.009140:0.002604:0.006536:0.002614:0.003911:0.005229:0.005218:0.006525:0.002614:0.001307:0.006525:0.005229:0.005229:0.002614:0.005229:0.003922:0.005229:0.001435:0.005229:0.005229:0.006584:0.002614:0.005229:0.005229:0.005229:0.005229:0.002614:0.002604:0.005229:0.002614:0.002614:0.002604:0.006536:0.002614:0.005229:0.005229:0.003911:0.003922:0.002604:0.006536:0.005229:0.003922:0.005229:0.003922:0.005218:0.005229:0.005908
 :@0.606013:0.984821:0.609673:0.984821:0.609673:0.970680:0.606013:0.970680:0.003660
Parameter :@0.126961:0.111925:0.211520:0.111925:0.211520:0.098793:0.126961:0.098793:0.010458:0.009108:0.006576:0.009108:0.014410:0.009142:0.006525:0.009142:0.006688:0.003399
Valid values :@0.319363:0.111925:0.415703:0.111925:0.415703:0.098793:0.319363:0.098793:0.010434:0.009159:0.005234:0.005217:0.009142:0.002617:0.009125:0.009108:0.005268:0.009142:0.009142:0.009350:0.003399
Effect :@0.571977:0.111925:0.622516:0.111925:0.622516:0.098793:0.571977:0.098793:0.010434:0.006525:0.006525:0.009142:0.007851:0.006662:0.003399
scoring :@0.126961:0.302051:0.186650:0.302051:0.186650:0.288920:0.126961:0.288920:0.009125:0.007851:0.009142:0.006542:0.005217:0.009142:0.009270:0.003399
'accuracy', :@0.319363:0.133908:0.437875:0.133908:0.437875:0.120501:0.319363:0.120501:0.010434:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010196
'adjusted_rand_score', :@0.319363:0.148087:0.546192:0.148087:0.546192:0.134680:0.319363:0.134680:0.010434:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.010196
'average_precision', :@0.319363:0.162229:0.526615:0.162229:0.526615:0.148822:0.319363:0.148822:0.010434:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.010196
'f1', 'f1_macro', :@0.319363:0.176395:0.496605:0.176395:0.496605:0.162988:0.319363:0.162988:0.010434:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010196
'f1_micro', :@0.319363:0.190537:0.437875:0.190537:0.437875:0.177130:0.319363:0.177130:0.010434:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010196
'f1_samples', :@0.319363:0.205688:0.457452:0.205688:0.457452:0.192281:0.319363:0.192281:0.010434:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010196
'f1_weighted', :@0.319363:0.219855:0.467886:0.219855:0.467886:0.206448:0.319363:0.206448:0.010434:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.010196
'log_loss', :@0.319363:0.233996:0.437875:0.233996:0.437875:0.220589:0.319363:0.220589:0.010434:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010196
'mean_absolute_error', :@0.319363:0.248176:0.546192:0.248176:0.546192:0.234769:0.319363:0.234769:0.010434:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.010196
'mean_squared_error', :@0.319363:0.262317:0.535758:0.262317:0.535758:0.248910:0.319363:0.248910:0.010434:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010196
'median_absolute_error', :@0.319363:0.276496:0.564476:0.276496:0.564476:0.263089:0.319363:0.263089:0.010434:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.009142:0.010196
'precision', :@0.319363:0.291648:0.448309:0.291648:0.448309:0.278241:0.319363:0.278241:0.010434:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.010196
'precision_macro', :@0.319363:0.305815:0.507039:0.305815:0.507039:0.292408:0.319363:0.292408:0.010434:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.010196
'precision_micro', :@0.319363:0.319956:0.507039:0.319956:0.507039:0.306549:0.319363:0.306549:0.010434:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.010196
'precision_samples', :@0.319363:0.334123:0.526887:0.334123:0.526887:0.320716:0.319363:0.320716:0.010434:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010706:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.010196
'precision_weighted', :@0.319363:0.348264:0.535758:0.348264:0.535758:0.334857:0.319363:0.334857:0.010434:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010196
'r2', 'recall', :@0.319363:0.362406:0.477028:0.362406:0.477028:0.348998:0.319363:0.348998:0.010434:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010196
'recall_macro', :@0.319363:0.377595:0.477028:0.377595:0.477028:0.364188:0.319363:0.364188:0.010434:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010196
'recall_micro', :@0.319363:0.391736:0.477028:0.391736:0.477028:0.378329:0.319363:0.378329:0.010434:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010196
'recall_samples', :@0.319363:0.405903:0.496605:0.405903:0.496605:0.392496:0.319363:0.392496:0.010434:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010196
'recall_weighted', :@0.319363:0.420057:0.507039:0.420057:0.507039:0.406650:0.319363:0.406650:0.010434:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.010196
'roc_auc' or a callable :@0.319363:0.434224:0.555334:0.434224:0.555334:0.420817:0.319363:0.420817:0.010434:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010196
function with signature :@0.319363:0.448365:0.555334:0.448365:0.555334:0.434958:0.319363:0.434958:0.010434:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010196
scorer(y_true, y_pred) :@0.319363:0.462532:0.545539:0.462532:0.545539:0.449125:0.319363:0.449125:0.010434:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.009782:0.010196
Function used to evaluate the quality of a :@0.571977:0.245422:0.869295:0.245422:0.869295:0.232291:0.571977:0.232291:0.009142:0.009142:0.009142:0.007851:0.005234:0.003925:0.009142:0.009142:0.003908:0.009142:0.007851:0.009142:0.009142:0.002617:0.005234:0.009142:0.002617:0.009142:0.007851:0.009125:0.005217:0.009142:0.009125:0.005234:0.009142:0.002617:0.005234:0.009142:0.009142:0.002617:0.009142:0.009142:0.009125:0.005217:0.003925:0.005234:0.007851:0.002617:0.009142:0.005234:0.003908:0.009125:0.003399
given pipeline for the problem. By :@0.571977:0.261584:0.819952:0.261584:0.819952:0.248453:0.571977:0.248453:0.009142:0.003925:0.007851:0.009142:0.009142:0.003908:0.009142:0.003925:0.009142:0.009142:0.005217:0.003925:0.009142:0.009142:0.002617:0.005234:0.009142:0.006525:0.002617:0.005234:0.009142:0.009441:0.003922:0.009142:0.006525:0.009142:0.009142:0.005217:0.009142:0.014359:0.005217:0.002617:0.010451:0.007851:0.003399
default, balanced accuracy is used for :@0.571977:0.277783:0.847084:0.277783:0.847084:0.264652:0.571977:0.264652:0.009142:0.009142:0.005234:0.009125:0.009142:0.005217:0.005234:0.005217:0.002617:0.009142:0.009125:0.005217:0.009125:0.009142:0.007851:0.009142:0.009142:0.002617:0.009125:0.007851:0.007851:0.009142:0.006525:0.009125:0.007851:0.007851:0.002617:0.003925:0.007851:0.002617:0.009142:0.007851:0.009142:0.009142:0.002617:0.005234:0.009142:0.006525:0.003399
classification and mean squared error is :@0.571977:0.293945:0.862752:0.293945:0.862752:0.280814:0.571977:0.280814:0.007851:0.005217:0.009125:0.007851:0.007851:0.003925:0.005234:0.003925:0.007851:0.009125:0.005234:0.003925:0.009142:0.009142:0.002617:0.009125:0.009142:0.009142:0.002617:0.014359:0.009142:0.009125:0.009142:0.002617:0.007851:0.009142:0.009142:0.009125:0.006525:0.009142:0.009142:0.002617:0.009142:0.006525:0.006525:0.009142:0.006525:0.002617:0.003925:0.007851:0.003399
used for regression. TPOT assumes that :@0.571977:0.310132:0.862769:0.310132:0.862769:0.297001:0.571977:0.297001:0.009142:0.007851:0.009142:0.009142:0.002617:0.005234:0.009142:0.006525:0.002617:0.006525:0.009142:0.009142:0.006525:0.009142:0.007851:0.007851:0.003925:0.009142:0.009142:0.005217:0.002617:0.009142:0.010434:0.011742:0.009142:0.002617:0.009125:0.007851:0.007851:0.009142:0.014359:0.009142:0.007851:0.002617:0.005234:0.009142:0.009125:0.005234:0.003399
any function with \error\ or \loss\ in the :@0.571977:0.326293:0.858929:0.326293:0.858929:0.313162:0.571977:0.313162:0.009125:0.009142:0.007851:0.002617:0.005234:0.009142:0.009142:0.007851:0.005234:0.003925:0.009142:0.009142:0.003908:0.013102:0.003892:0.005234:0.009142:0.003908:0.006542:0.009142:0.006525:0.006525:0.009142:0.006525:0.006542:0.002617:0.009142:0.006525:0.002617:0.006542:0.005217:0.009142:0.007851:0.007851:0.006542:0.002617:0.003925:0.009142:0.002617:0.005234:0.009142:0.009142:0.003399
name is meant to be minimized, whereas :@0.571977:0.342493:0.870586:0.342493:0.870586:0.329362:0.571977:0.329362:0.009142:0.009125:0.014359:0.009142:0.002617:0.003925:0.007851:0.002617:0.014359:0.009142:0.009125:0.009142:0.005234:0.002617:0.005234:0.009142:0.002617:0.009142:0.009142:0.003908:0.014359:0.003925:0.009142:0.003925:0.014359:0.003925:0.007851:0.009142:0.009142:0.005217:0.002617:0.013102:0.009125:0.009142:0.006525:0.009142:0.009125:0.007851:0.003399
any other functions will be maximized. :@0.571977:0.358655:0.852876:0.358655:0.852876:0.345523:0.571977:0.345523:0.009125:0.009142:0.007851:0.002617:0.009142:0.005234:0.009142:0.009142:0.006525:0.002617:0.005234:0.009142:0.009142:0.007851:0.005234:0.003925:0.009142:0.009142:0.007851:0.003908:0.013102:0.003892:0.005217:0.005217:0.002617:0.009142:0.009142:0.002617:0.014359:0.009125:0.007885:0.003875:0.014359:0.003925:0.007851:0.009142:0.009142:0.005775:0.003399
max_time_mins :@0.126961:0.514362:0.249477:0.514362:0.249477:0.501230:0.126961:0.501230:0.014379:0.009192:0.009125:0.007851:0.006525:0.005217:0.014359:0.007851:0.007851:0.014359:0.003925:0.009142:0.009340:0.003399
Any positive integer :@0.319363:0.514362:0.465441:0.514362:0.465441:0.501230:0.319363:0.501230:0.010434:0.009142:0.007851:0.002617:0.009142:0.009142:0.007851:0.003925:0.005234:0.003925:0.007851:0.009142:0.003908:0.003925:0.009142:0.005234:0.009142:0.009142:0.009142:0.006783:0.003399
How many minutes TPOT has to optimize :@0.571977:0.497190:0.867986:0.497190:0.867986:0.484059:0.571977:0.484059:0.011742:0.009142:0.013102:0.002583:0.014359:0.009125:0.009142:0.007851:0.002617:0.014359:0.003925:0.009142:0.009142:0.005234:0.009142:0.007851:0.002617:0.009142:0.010434:0.011742:0.009142:0.002617:0.009142:0.009125:0.007851:0.002617:0.005234:0.009142:0.002617:0.009142:0.009142:0.005234:0.003925:0.014359:0.003925:0.007851:0.009142:0.003399
the pipeline. This setting will override the :@0.571977:0.513352:0.873254:0.513352:0.873254:0.500220:0.571977:0.500220:0.005234:0.009142:0.009142:0.003908:0.009142:0.003925:0.009142:0.009142:0.005217:0.003925:0.009142:0.009142:0.005217:0.002617:0.009142:0.009142:0.003925:0.007851:0.002617:0.007851:0.009142:0.005234:0.005234:0.003925:0.009142:0.009142:0.003908:0.013102:0.003892:0.005217:0.005217:0.002617:0.009142:0.007851:0.009142:0.006525:0.006525:0.003925:0.009142:0.009142:0.002617:0.005234:0.009142:0.009142:0.003399
generations:@0.571977:0.528252:0.684131:0.528252:0.684131:0.514844:0.571977:0.514844:0.010458:0.010458:0.010458:0.010458:0.010458:0.010458:0.010458:0.009149:0.010458:0.009149:0.010196
 parameter. :@0.684559:0.529538:0.770392:0.529538:0.770392:0.516407:0.684559:0.516407:0.002614:0.009142:0.009125:0.005234:0.009125:0.013068:0.009142:0.005234:0.009142:0.006525:0.004080:0.003399
random_state :@0.126961:0.595258:0.236373:0.595258:0.236373:0.582127:0.126961:0.582127:0.006542:0.009108:0.009193:0.009142:0.009142:0.014359:0.007851:0.009125:0.006525:0.009108:0.006559:0.009354:0.003399
Any positive integer :@0.319363:0.595258:0.465441:0.595258:0.465441:0.582127:0.319363:0.582127:0.010434:0.009142:0.007851:0.002617:0.009142:0.009142:0.007851:0.003925:0.005234:0.003925:0.007851:0.009142:0.003908:0.003925:0.009142:0.005234:0.009142:0.009142:0.009142:0.006783:0.003399
The random number generator seed for :@0.571977:0.562910:0.860084:0.562910:0.860084:0.549778:0.571977:0.549778:0.009142:0.009142:0.009142:0.002617:0.006525:0.009125:0.009142:0.009142:0.009142:0.014359:0.002617:0.009142:0.009142:0.014359:0.009142:0.009142:0.006525:0.002617:0.009142:0.009142:0.009142:0.009142:0.006525:0.009125:0.005234:0.009142:0.006525:0.002617:0.007851:0.009142:0.009142:0.009142:0.002617:0.005234:0.009142:0.006525:0.003399
TPOT. Use this to make sure that TPOT :@0.571977:0.579071:0.852267:0.579071:0.852267:0.565940:0.571977:0.565940:0.009142:0.010434:0.011742:0.009142:0.005217:0.002617:0.011725:0.007885:0.009142:0.002617:0.005234:0.009142:0.003925:0.007851:0.002617:0.005234:0.009142:0.002617:0.014359:0.009125:0.009125:0.009142:0.002617:0.007851:0.009142:0.006525:0.009142:0.002617:0.005234:0.009142:0.009125:0.005234:0.002617:0.009142:0.010434:0.011742:0.009142:0.003399
will give you the same results each time :@0.571977:0.595258:0.861601:0.595258:0.861601:0.582127:0.571977:0.582127:0.013102:0.003892:0.005217:0.005217:0.002617:0.009142:0.004032:0.007851:0.009142:0.002617:0.007851:0.009142:0.009142:0.003908:0.005234:0.009142:0.009142:0.002617:0.007851:0.009125:0.014359:0.009142:0.002617:0.006525:0.009142:0.007851:0.009142:0.005217:0.005234:0.007851:0.002617:0.009142:0.009125:0.007851:0.009142:0.002617:0.005234:0.003925:0.014359:0.009142:0.003399
you run it against the same dataset with :@0.571977:0.611420:0.860152:0.611420:0.860152:0.598288:0.571977:0.598288:0.007851:0.009142:0.009142:0.002617:0.006525:0.009142:0.009142:0.003908:0.003925:0.005234:0.003908:0.009125:0.009142:0.009125:0.003925:0.009142:0.007851:0.005234:0.002617:0.005234:0.009142:0.009142:0.002617:0.007851:0.009125:0.014359:0.009142:0.002617:0.009142:0.009125:0.005234:0.009125:0.007851:0.009142:0.005234:0.002617:0.013102:0.003892:0.005234:0.009142:0.003399
that seed. :@0.571977:0.627619:0.647353:0.627619:0.647353:0.614488:0.571977:0.614488:0.005234:0.009142:0.009125:0.005234:0.002617:0.007851:0.009142:0.009142:0.009142:0.005346:0.003399
verbosity :@0.126961:0.694349:0.203644:0.694349:0.203644:0.681218:0.126961:0.681218:0.009125:0.009142:0.006542:0.009142:0.009142:0.009125:0.005217:0.006525:0.009321:0.003399
{0, 1, 2, 3} :@0.319363:0.690032:0.447369:0.690032:0.447369:0.676625:0.319363:0.676625:0.010434:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.009494:0.010196
How much information TPOT :@0.571977:0.659968:0.783036:0.659968:0.783036:0.646836:0.571977:0.646836:0.011742:0.009142:0.013102:0.002583:0.014359:0.009142:0.007851:0.009142:0.002617:0.003925:0.009142:0.005234:0.009142:0.006525:0.014359:0.009125:0.005234:0.003925:0.009142:0.009142:0.002617:0.009142:0.010434:0.011742:0.009142:0.003399
communicates while it's running.   = :@0.571977:0.675119:0.838448:0.675119:0.838448:0.661988:0.571977:0.661988:0.007851:0.009142:0.014359:0.014359:0.009142:0.009142:0.003925:0.007851:0.009125:0.005234:0.009142:0.007851:0.002617:0.013102:0.009125:0.003925:0.005217:0.009142:0.002617:0.003925:0.005234:0.003925:0.007851:0.002617:0.006525:0.009142:0.009142:0.009142:0.003925:0.009142:0.009142:0.005217:0.003399:0.010102:0.002614:0.009150:0.003399
0:@0.812827:0.673832:0.823023:0.673832:0.823023:0.660425:0.812827:0.660425:0.010196
none,   = minimal,   = high,   = all. A :@0.571977:0.692329:0.839620:0.692329:0.839620:0.679197:0.571977:0.679197:0.009142:0.009142:0.009142:0.009142:0.005217:0.003399:0.009798:0.002614:0.009176:0.002583:0.014359:0.003925:0.009142:0.003925:0.014359:0.009125:0.005217:0.005217:0.003399:0.009897:0.002598:0.009176:0.002583:0.009142:0.003925:0.009142:0.009142:0.005217:0.003399:0.009808:0.002598:0.009176:0.002583:0.009125:0.005217:0.005217:0.005217:0.002617:0.010434:0.003399
1:@0.616503:0.691042:0.626699:0.691042:0.626699:0.677635:0.616503:0.677635:0.010196
2:@0.709428:0.691042:0.719624:0.691042:0.719624:0.677635:0.709428:0.677635:0.010196
3:@0.773578:0.691042:0.783775:0.691042:0.783775:0.677635:0.773578:0.677635:0.010196
setting of   or higher will add a progress :@0.571977:0.709501:0.865518:0.709501:0.865518:0.696369:0.571977:0.696369:0.007851:0.009142:0.005234:0.005234:0.003925:0.009142:0.009142:0.003908:0.009142:0.005234:0.003399:0.009805:0.002631:0.009142:0.006525:0.003908:0.009142:0.003925:0.009142:0.009142:0.009142:0.006525:0.002617:0.013102:0.003892:0.005217:0.005217:0.002617:0.009125:0.009142:0.009142:0.002617:0.009125:0.002617:0.009142:0.006525:0.009142:0.009142:0.006525:0.009142:0.007851:0.007851:0.003399
2:@0.642647:0.708214:0.652843:0.708214:0.652843:0.694807:0.642647:0.694807:0.010196
bar to calls to :@0.571977:0.726710:0.672035:0.726710:0.672035:0.713579:0.571977:0.713579:0.009142:0.009125:0.006525:0.002617:0.005234:0.009142:0.002617:0.007851:0.009125:0.005217:0.005217:0.007851:0.002617:0.005234:0.009142:0.003399
fit():@0.671438:0.725423:0.723464:0.725423:0.723464:0.712016:0.671438:0.712016:0.010458:0.010458:0.010458:0.010458:0.010196
. :@0.723824:0.726710:0.732451:0.726710:0.732451:0.713579:0.723824:0.713579:0.005229:0.003399
disable_update_check :@0.126961:0.768149:0.297876:0.768149:0.297876:0.755018:0.126961:0.755018:0.009142:0.005217:0.009125:0.009108:0.009193:0.005234:0.009142:0.007851:0.009142:0.009142:0.009142:0.009108:0.006559:0.009142:0.007851:0.007851:0.009142:0.009142:0.007851:0.009426:0.003399
[True, False] :@0.319363:0.764842:0.457827:0.764842:0.457827:0.751435:0.319363:0.751435:0.010434:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009142:0.010434:0.009518:0.010196
Flag indicating whether the TPOT version :@0.571977:0.759059:0.871912:0.759059:0.871912:0.745927:0.571977:0.745927:0.009142:0.005217:0.009125:0.009142:0.002617:0.003925:0.009142:0.009142:0.003925:0.007851:0.009125:0.005234:0.003925:0.009142:0.009142:0.003908:0.013102:0.009125:0.009142:0.005234:0.009142:0.009142:0.006525:0.002617:0.005234:0.009142:0.009142:0.002617:0.009142:0.010434:0.011742:0.009142:0.002617:0.007851:0.009142:0.006525:0.007851:0.003925:0.009142:0.009142:0.003399
checker should be disabled. :@0.571977:0.775258:0.778268:0.775258:0.778268:0.762127:0.571977:0.762127:0.007851:0.009142:0.009142:0.007851:0.009125:0.009142:0.006525:0.002617:0.007851:0.009142:0.009142:0.009142:0.005217:0.009142:0.002617:0.009142:0.009142:0.002617:0.009142:0.003925:0.007851:0.009125:0.009142:0.005217:0.009142:0.009142:0.005649:0.003399
Further details can be found at :@0.188480:0.822758:0.411765:0.822758:0.411765:0.809627:0.188480:0.809627:0.009142:0.009142:0.006525:0.005234:0.009142:0.009142:0.006525:0.002617:0.009142:0.009142:0.005234:0.009125:0.003925:0.005217:0.007851:0.002617:0.007851:0.009125:0.009142:0.002617:0.009142:0.009142:0.002617:0.005234:0.009142:0.009142:0.009142:0.009142:0.003908:0.009125:0.005683:0.003399
Using TPOT:@0.410980:0.822758:0.496152:0.822758:0.496152:0.809627:0.410980:0.809627:0.011725:0.007885:0.003925:0.009142:0.009142:0.002617:0.009142:0.010434:0.011742:0.009414
.  :@0.496078:0.822758:0.507320:0.822758:0.507320:0.809627:0.496078:0.809627:0.005228:0.002615:0.003399
 :@0.117810:0.863187:0.121209:0.863187:0.121209:0.850056:0.117810:0.850056:0.003399
 :@0.353382:0.863187:0.356781:0.863187:0.356781:0.850056:0.353382:0.850056:0.003399